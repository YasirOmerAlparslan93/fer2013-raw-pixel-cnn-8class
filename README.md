# Ham Piksel Verisinden YÃ¼z Ä°fadesi TanÄ±ma iÃ§in Derin Ã–ÄŸrenme TabanlÄ± CNN Modeli (FER2013 â€“ 8 SÄ±nÄ±f)
*(A Deep Learningâ€“Based CNN Model for Facial Expression Recognition from Raw Pixel Data)*

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)
![Accuracy](https://img.shields.io/badge/Test%20Accuracy-71.8%25-success.svg)

---

**GitHub Repository Name:** `fer2013-raw-pixel-cnn-8class`  
**Course:** Derin Ã–ÄŸrenme ve UygulamalarÄ±  
**Student:** <YASÄ°R Ã–MER ALPARSLAN ((KERKÃœKLÃœ - KARKOUKLI))> (<STUDENT ID 244225708 >)   
**Instructor:** Ã–ÄŸr. Ãœyesi Dr. Selim YÄ±lmaz  
**Date:** December 2025 â€“ January 2026  

---

## Abstract / Ã–zet

**EN:**  
This study presents a lightweight convolutional neural network (CNN) for facial expression recognition (FER) using the FER2013 dataset, relying solely on raw pixel data (48Ã—48 grayscale).  
Unlike classical approaches based on hand-crafted features (HOG, LBP, SIFT), the proposed model learns discriminative representations end-to-end directly from pixels.  
Experimental results show that a compact CNN can achieve competitive performance on low-resolution facial emotion classification.

**TR:**  
Bu Ã§alÄ±ÅŸmada, FER2013 veri seti kullanÄ±larak yalnÄ±zca ham piksel verisine (48Ã—48 gri seviye) dayanan hafif bir evriÅŸimsel sinir aÄŸÄ± (CNN) sunulmaktadÄ±r.  
Elle Ã§Ä±karÄ±lmÄ±ÅŸ Ã¶zniteliklere (HOG, LBP, SIFT) dayanan klasik yaklaÅŸÄ±mlarÄ±n aksine, Ã¶nerilen model uÃ§tan uca (end-to-end) biÃ§imde doÄŸrudan piksellerden Ã¶ÄŸrenir.  
Deneysel sonuÃ§lar, kÃ¼Ã§Ã¼k ve hafif bir CNN mimarisinin dÃ¼ÅŸÃ¼k Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ yÃ¼z ifadeleri iÃ§in rekabetÃ§i performans saÄŸlayabildiÄŸini gÃ¶stermektedir.

---

## 1. Problem Definition / Problem TanÄ±mÄ±

**TR:**  
Bu proje, FER2013 veri setindeki yÃ¼z gÃ¶rÃ¼ntÃ¼lerinden ham piksel verisi (48Ã—48 gri seviye) kullanarak duygu sÄ±nÄ±flandÄ±rmasÄ± yapmayÄ± hedefler.  
Model, elle Ã¶znitelik Ã§Ä±karÄ±mÄ± (HOG / LBP / SIFT) veya klasik makine Ã¶ÄŸrenmesi yÃ¶ntemleri olmadan, uÃ§tan uca bir CNN mimarisi ile eÄŸitilmiÅŸtir.

**EN:**  
This project performs facial expression recognition on the FER2013 dataset using raw pixel data only (48Ã—48 grayscale).  
No hand-crafted feature extraction or classical machine learning methods are employed; the CNN learns representations end-to-end.

**Classes (8):**  
Anger, Contempt, Disgust, Fear, Happiness, Neutral, Sadness, Surprise

---

## 2. Dataset & Preprocessing / Veri Seti ve Ã–n Ä°ÅŸleme

**EN:**  
- Dataset: FER2013 (48Ã—48 grayscale facial images)  
- Normalization: pixel values scaled to [0, 1]  
- Data Augmentation (optional): small rotations, horizontal flipping, brightness/contrast jitter  
- Class imbalance handling (optional): class_weight, balanced sampling  

**TR:**  
- **Veri Seti:** FER2013 (48Ã—48 gri seviye yÃ¼z gÃ¶rÃ¼ntÃ¼leri)  
- **Normalizasyon:** piksel deÄŸerleri [0, 1] aralÄ±ÄŸÄ±na Ã¶lÃ§eklenir  
- **Veri ArtÄ±rma (opsiyonel):** kÃ¼Ã§Ã¼k dÃ¶ndÃ¼rme, yatay Ã§evirme, parlaklÄ±k/kontrast deÄŸiÅŸimleri  
- **SÄ±nÄ±f dengesizliÄŸi:** class_weight veya dengeli Ã¶rnekleme  

âš ï¸ *Not:* Bu repo, â€œham piksel + derin Ã¶ÄŸrenmeâ€ ÅŸartÄ±na uygun olarak tasarlanmÄ±ÅŸtÄ±r.

---

## 3. Model Architecture & Rationale / Model Mimarisi ve GerekÃ§esi

**Architecture:**  
- Input: 48 Ã— 48 Ã— 1  
- Conv Blocks: Conv2D â†’ BatchNorm â†’ ReLU â†’ MaxPooling  
- Regularization: Dropout  
- Classifier: Fully Connected + Softmax  
- Loss: Categorical Cross-Entropy  
- Optimizer: Adam  

**Motivation / GerekÃ§e:**  
Low-resolution facial images require lightweight yet expressive architectures to avoid overfitting while maintaining generalization ability.  
DÃ¼ÅŸÃ¼k Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ yÃ¼z gÃ¶rÃ¼ntÃ¼leri iÃ§in aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nleyen, ancak genelleme yeteneÄŸini koruyan hafif CNN mimarileri tercih edilmiÅŸtir.

---

## 4. Installation / Kurulum

```bash
pip install -r requirements.txt
```

- Python 3.10+ recommended  
- TensorFlow / Keras backend  

---

## 5. How to Run / Ã‡alÄ±ÅŸtÄ±rma

Option 1 â€“ Same Directory Structure (Simple Setup)

English

You can place the entire FER2013 dataset inside a folder named fer2013, located in the same directory as the training code file.

The training code is contained in the Jupyter Notebook (or Python script) named:

Tam kodu eÄŸitim.py 
YÃ¼z Ä°fadesi TanÄ±ma CNN DL-last.ipynb
Recommended directory structure:


---

project_root/

```
project_root/
â”‚
â”œâ”€â”€ fer2013/
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ validation/
â”‚   â””â”€â”€ test/
â”‚
â”œâ”€â”€ YÃ¼z Ä°fadesi TanÄ±ma CNN DL-last.ipynb
â””â”€â”€ Tam kodu eÄŸitim.py
After verifying that the dataset folders are correctly placed, simply open the notebook and run all cells sequentially, or execute the Python script to start training.

TÃ¼rkÃ§e
SeÃ§enek 1 â€“ AynÄ± Dizin YapÄ±sÄ± (Basit Kurulum)

FER2013 veri setinin tamamÄ±nÄ± fer2013 adlÄ± bir klasÃ¶r altÄ±na yerleÅŸtirerek, eÄŸitim kodu ile aynÄ± dizinde bulundurabilirsiniz.

EÄŸitim kodu ÅŸu dosyalardan birinde yer almaktadÄ±r:

nginx
Tam kodu eÄŸitim.py
veya

YÃ¼z Ä°fadesi TanÄ±ma CNN DL-last.ipynb
Ã–nerilen klasÃ¶r yapÄ±sÄ±:

---

proje_dizini/

```
proje_dizini/
â”‚
â”œâ”€â”€ fer2013/
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ validation/
â”‚   â””â”€â”€ test/
â”‚
â”œâ”€â”€ YÃ¼z Ä°fadesi TanÄ±ma CNN DL-last.ipynb
â””â”€â”€ Tam kodu eÄŸitim.py
KlasÃ¶r yapÄ±sÄ±nÄ±n doÄŸru olduÄŸundan emin olduktan sonra, notebook iÃ§indeki tÃ¼m hÃ¼creleri sÄ±rasÄ±yla Ã§alÄ±ÅŸtÄ±rmanÄ±z veya Python dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rmanÄ±z yeterlidir.

Option 2 â€“ Custom Dataset Path


### Training / EÄŸitim
```bash
python src/train.py --config configs/config.yaml
```

### Evaluation / DeÄŸerlendirme
```bash
python src/eval.py --weights models/best_emotion_cnn_8class.keras
```

### Inference (Single Image) / Tek GÃ¶rÃ¼ntÃ¼
```bash
python src/infer.py --image path/to/image.png --weights models/best_emotion_cnn_8class.keras
```

*Note:* Even if development was done in notebooks, script-based entry points are provided for reproducibility and grading.

---

## 6. Repository Structure

```
fer2013-raw-pixel-cnn-8class/
â”œâ”€ src/
â”‚  â”œâ”€ train.py
â”‚  â”œâ”€ eval.py
â”‚  â”œâ”€ infer.py
â”‚  â””â”€ utils.py
   â”œâ”€Tam kodu eÄŸitim.py
   â””â”€YÃ¼z Ä°fadesi TanÄ±ma CNN DL-last.ipynb
â”œâ”€ configs/
â”‚  â””â”€ config.yaml
â”œâ”€ models/
â”‚  â””â”€ epoch_x/
â”‚     â”œâ”€ best_emotion_cnn_8class.keras
â”‚     â””â”€ final_emotion_cnn_8class.keras
â”œâ”€ outputs/
â”‚  â”œâ”€ figures/
â”‚  â”‚  â””â”€ epoch_x/
â”‚  â”‚    â”œâ”€accuracy_curve_8class.jpg
â”‚  â”‚    â”œâ”€ loss_curve_8class.jpg
â”‚  â”‚    â”œâ”€ confusion_matrix_counts_8class.jpg
â”‚  â”‚    â”œâ”€ confusion_matrix_normalized_8class.jpg
â”‚  â”‚    â”œâ”€ sample_predictions_8class.jpg
â”‚  â”‚    â””â”€ gradcam_samples_8class.jpg
â”‚  â””â”€ metrics/
â”‚     â””â”€ epoch_x/
â”‚        â””â”€ classification_report_8class.txt
â”œâ”€ presentation/
â”‚  â””â”€ final_presentation.pdf
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## 7. Experimental Results / Deneysel SonuÃ§lar

**Quantitative Metrics:**  
- Test Accuracy: **0.7181**  
- Test Loss: **0.9193**  
- Weighted F1-Score: **0.6908**  
- Macro F1-Score: **0.4184**

Lower performance is observed for *Contempt*, *Disgust*, and *Fear* due to class imbalance and limited samples.

### Training Curves
![Accuracy](outputs/figures/epoch 15/accuracy_curve_8class.jpg)  
![Loss](outputs/figures/epoch 15/loss_curve_8class.jpg)
![Accuracy](outputs/figures/epoch 60/accuracy_curve_8class.jpg)  
![Loss](outputs/figures/epoch 60/loss_curve_8class.jpg)
![Accuracy](outputs/figures/epoch 360/accuracy_curve_8class.jpg)  
![Loss](outputs/figures/epoch 360/loss_curve_8class.jpg)
### Confusion Matrices
![Counts](outputs/figures/epoch 15/confusion_matrix_counts_8class.jpg)  
![Normalized](outputs/figures/epoch 15/confusion_matrix_normalized_8class.jpg)

![Counts](outputs/figures/epoch 60/confusion_matrix_counts_8class.jpg)  
![Normalized](outputs/figures/epoch 60/confusion_matrix_normalized_8class.jpg)

![Counts](outputs/figures/epoch 360/confusion_matrix_counts_8class.jpg)  
![Normalized](outputs/figures/epoch 360/confusion_matrix_normalized_8class.jpg)
### Sample Predictions
![Samples](outputs/figures/epoch 15/sample_predictions_8class.jpg)

### Grad-CAM Visualizations
![GradCAM](outputs/figures/gradcam/gradcam_samples_8class.jpg)

Model attention focuses mainly on eyes, mouth, and facial muscles, confirming meaningful spatial reasoning.

---

## 8. Presentation / Sunum

ğŸ“„ `presentation/Emotion_CNN_8Class_Presentation.pdf`  

All experiments and figures in the presentation exactly match the repository content.

---

## Acknowledgements / TeÅŸekkÃ¼r

- FER2013 Dataset (public / Kaggle mirror):  
  https://www.kaggle.com/code/pedroadorighello/gradcam-fer2013-test/input?select=fer2013plus  
- TensorFlow / Keras  

---

## Keywords
Facial Expression Recognition Â· CNN Â· Deep Learning Â· FER2013 Â· Raw Pixels Â· Grad-CAM
