{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d258aa-af7c-4259-83d0-ad9a630e8212",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d306684a-7d33-49c6-948b-0a318aab3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3cb1bc-8030-429a-99f2-7b1589662502",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install torch torchvision torchaudio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6248ef4e-fa30-44d7-a364-cce30de18245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef2f29a-3730-48bd-a969-42dfc5455553",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2443f2-78bb-4103-895c-4bd258bd335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install \"protobuf<6,>=3.20\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f038eba-d513-4bc5-b642-7c6bb16d4f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import google.protobuf\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"Protobuf:\", google.protobuf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daac390-9c81-4191-a6ee-576fd1af23f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 1 – Imports and general configuration\n",
    "# Hücre 1 – Kütüphaneler ve genel ayarlar\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Dataset directories\n",
    "# Veri seti dizinleri\n",
    "DATA_DIR = \"./fer2013\"          # Contains train/ and test/\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "TEST_DIR  = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "# Optional external images directory\n",
    "# Harici test görüntüleri (isteğe bağlı)\n",
    "EXTERNAL_IMAGES_DIR = \"./external_images\"\n",
    "\n",
    "# Results directory\n",
    "# Sonuçların kaydedileceği klasör\n",
    "RESULTS_DIR = \"./training_results\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Global constants\n",
    "# Genel sabitler\n",
    "IMG_SIZE = (48, 48)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Solution B: 8 classes (including contempt)\n",
    "# Çözüm B: 8 sınıf (contempt dahil)\n",
    "NUM_CLASSES = 8\n",
    "CLASS_NAMES = [\"anger\", \"contempt\", \"disgust\", \"fear\",\n",
    "               \"happiness\", \"neutral\", \"sadness\", \"surprise\"]\n",
    "\n",
    "EMOTION_LABELS = [\"Anger\", \"Contempt\", \"Disgust\", \"Fear\",\n",
    "                  \"Happiness\", \"Neutral\", \"Sadness\", \"Surprise\"]\n",
    "\n",
    "# Number of epochs (minimum 15-60 as requested)\n",
    "# Epoch sayısı (istenildiği gibi minimum 15-60)\n",
    "EPOCHS = 15\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 2 – Load training, validation and test datasets\n",
    "# Hücre 2 – Eğitim, doğrulama ve test verilerinin yüklenmesi\n",
    "# ============================================================\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=CLASS_NAMES,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=CLASS_NAMES,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TEST_DIR,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=CLASS_NAMES,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Normalize images and convert labels to one-hot encoding\n",
    "# Görüntüleri normalize et ve etiketleri one-hot yap\n",
    "def preprocess(images, labels):\n",
    "    images = tf.cast(images, tf.float32) / 255.0\n",
    "    labels_one_hot = tf.one_hot(labels, depth=NUM_CLASSES)\n",
    "    return images, labels_one_hot\n",
    "\n",
    "train_ds = train_ds.map(preprocess)\n",
    "val_ds   = val_ds.map(preprocess)\n",
    "test_ds  = test_ds.map(preprocess)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds   = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds  = test_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 3 – Visualize sample images (optional)\n",
    "# Hücre 3 – Örnek görüntüleri göster (isteğe bağlı)\n",
    "# ============================================================\n",
    "\n",
    "def show_sample_batch(dataset, n=9):\n",
    "    images, labels = next(iter(dataset))\n",
    "    images = images.numpy()\n",
    "    labels = tf.argmax(labels, axis=1).numpy()\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    for i in range(min(n, len(images))):\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].squeeze(), cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(EMOTION_LABELS[labels[i]])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_sample_batch(train_ds)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 4 – Define CNN model from scratch\n",
    "# Hücre 4 – CNN modelinin sıfırdan tanımlanması\n",
    "# ============================================================\n",
    "\n",
    "def make_cnn(input_shape=(48, 48, 1), num_classes=NUM_CLASSES):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(32, (3, 3), padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name=\"emotion_cnn_8class\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "model = make_cnn()\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 5 – Callbacks (checkpoint and LR scheduler)\n",
    "# Hücre 5 – Callback’ler (model kaydı ve öğrenme oranı)\n",
    "# ============================================================\n",
    "\n",
    "checkpoint_path = os.path.join(RESULTS_DIR, \"best_emotion_cnn_8class.keras\")\n",
    "\n",
    "cb_list = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-5,\n",
    "        verbose=1\n",
    "    )\n",
    "    # EarlyStopping is not used to complete all epochs\n",
    "    # Tüm epoch’ları tamamlamak için EarlyStopping kullanılmadı\n",
    "]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 6 – Train the model\n",
    "# Hücre 6 – Modelin eğitilmesi\n",
    "# ============================================================\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=cb_list\n",
    ")\n",
    "\n",
    "final_model_path = os.path.join(RESULTS_DIR, \"final_emotion_cnn_8class.keras\")\n",
    "model.save(final_model_path)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 7 – Plot and save accuracy & loss curves\n",
    "# Hücre 7 – Doğruluk ve kayıp grafiklerinin çizilmesi\n",
    "# ============================================================\n",
    "\n",
    "def plot_and_save_history(history, results_dir=RESULTS_DIR):\n",
    "    # Accuracy curve\n",
    "    # Doğruluk grafiği\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(\"Training vs Validation Accuracy (8-class)\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    acc_path = os.path.join(results_dir, \"accuracy_curve_8class.jpg\")\n",
    "    plt.savefig(acc_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # Loss curve\n",
    "    # Kayıp grafiği\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.title(\"Training vs Validation Loss (8-class)\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    loss_path = os.path.join(results_dir, \"loss_curve_8class.jpg\")\n",
    "    plt.savefig(loss_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Saved:\", acc_path, \"and\", loss_path)\n",
    "\n",
    "plot_and_save_history(history)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 8 – Evaluate on test set and save classification report\n",
    "# Hücre 8 – Test verisi üzerinde değerlendirme\n",
    "# ============================================================\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for batch_images, batch_labels_one_hot in test_ds:\n",
    "    preds = model.predict(batch_images, verbose=0)\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "    y_true.extend(np.argmax(batch_labels_one_hot.numpy(), axis=1))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_ds, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "report = classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=EMOTION_LABELS,\n",
    "    digits=4\n",
    ")\n",
    "\n",
    "print(report)\n",
    "\n",
    "report_path = os.path.join(RESULTS_DIR, \"classification_report_8class.txt\")\n",
    "with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"Test Loss: {test_loss:.4f}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_acc:.4f}\\n\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "print(\"Saved report to:\", report_path)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 9 – Confusion matrix (raw and normalized)\n",
    "# Hücre 9 – Karışıklık matrisi (ham ve normalize)\n",
    "# ============================================================\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title=\"Confusion Matrix\"):\n",
    "    if normalize:\n",
    "        cm_show = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fmt = \".2f\"\n",
    "    else:\n",
    "        cm_show = cm\n",
    "        fmt = \"d\"\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm_show, interpolation=\"nearest\")\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm_show.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm_show.shape[0]), range(cm_show.shape[1])):\n",
    "        plt.text(\n",
    "            j, i,\n",
    "            format(cm_show[i, j], fmt),\n",
    "            ha=\"center\",\n",
    "            color=\"white\" if cm_show[i, j] > thresh else \"black\"\n",
    "        )\n",
    "\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Raw counts\n",
    "# Ham sayılar\n",
    "plot_confusion_matrix(cm, EMOTION_LABELS, normalize=False,\n",
    "                      title=\"Confusion Matrix (Counts) - 8 class\")\n",
    "cm_path = os.path.join(RESULTS_DIR, \"confusion_matrix_counts_8class.jpg\")\n",
    "plt.savefig(cm_path, dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Normalized matrix\n",
    "# Normalize edilmiş matris\n",
    "plot_confusion_matrix(cm, EMOTION_LABELS, normalize=True,\n",
    "                      title=\"Confusion Matrix (Normalized) - 8 class\")\n",
    "cm_norm_path = os.path.join(RESULTS_DIR, \"confusion_matrix_normalized_8class.jpg\")\n",
    "plt.savefig(cm_norm_path, dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved CM:\", cm_path, \"and\", cm_norm_path)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 10 – Show sample predictions from test set\n",
    "# Hücre 10 – Test setinden örnek tahminler\n",
    "# ============================================================\n",
    "\n",
    "def plot_sample_predictions(dataset, n=16,\n",
    "                            results_dir=RESULTS_DIR,\n",
    "                            filename=\"sample_predictions_8class.jpg\"):\n",
    "\n",
    "    images, labels_one_hot = next(iter(dataset))\n",
    "    images_np = images.numpy()\n",
    "    true_labels = np.argmax(labels_one_hot.numpy(), axis=1)\n",
    "\n",
    "    preds = model.predict(images, verbose=0)\n",
    "    pred_labels = np.argmax(preds, axis=1)\n",
    "\n",
    "    n = min(n, len(images_np))\n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    for i in range(n):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(images_np[i].squeeze(), cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        t = EMOTION_LABELS[true_labels[i]]\n",
    "        p = EMOTION_LABELS[pred_labels[i]]\n",
    "        color = \"green\" if true_labels[i] == pred_labels[i] else \"red\"\n",
    "\n",
    "        plt.title(f\"T:{t}\\nP:{p}\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_path = os.path.join(results_dir, filename)\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Saved:\", out_path)\n",
    "\n",
    "plot_sample_predictions(test_ds)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 11 – Predict external images and save results\n",
    "# Hücre 11 – Harici görüntüler için tahmin\n",
    "# ============================================================\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def predict_external_images(\n",
    "    folder_path=EXTERNAL_IMAGES_DIR,\n",
    "    model=model,\n",
    "    img_size=IMG_SIZE,\n",
    "    results_dir=RESULTS_DIR,\n",
    "    output_file=\"external_predictions_8class.txt\"\n",
    "):\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(\"No external_images folder. Skipping.\")\n",
    "        return\n",
    "\n",
    "    files = [f for f in os.listdir(folder_path)\n",
    "             if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "\n",
    "    if not files:\n",
    "        print(\"No images found in external_images.\")\n",
    "        return\n",
    "\n",
    "    out_lines = []\n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    for i, fname in enumerate(files[:16]):\n",
    "        img_path = os.path.join(folder_path, fname)\n",
    "\n",
    "        img = image.load_img(\n",
    "            img_path,\n",
    "            color_mode=\"grayscale\",\n",
    "            target_size=img_size\n",
    "        )\n",
    "\n",
    "        img_arr = image.img_to_array(img) / 255.0\n",
    "        img_arr = np.expand_dims(img_arr, axis=0)\n",
    "\n",
    "        pred = model.predict(img_arr, verbose=0)\n",
    "        pred_label_int = int(np.argmax(pred, axis=1)[0])\n",
    "        pred_label_name = EMOTION_LABELS[pred_label_int]\n",
    "\n",
    "        out_lines.append(\n",
    "            f\"{fname}\\t{pred_label_int}\\t{pred_label_name}\\t{pred[0]}\"\n",
    "        )\n",
    "\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(img_arr[0].squeeze(), cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(pred_label_name)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    ext_fig_path = os.path.join(\n",
    "        results_dir,\n",
    "        \"external_images_predictions_8class.jpg\"\n",
    "    )\n",
    "    plt.savefig(ext_fig_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    out_path = os.path.join(results_dir, output_file)\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"filename\\tpred_label_id\\tpred_label_name\\tprob_vector\\n\")\n",
    "        for line in out_lines:\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "    print(\"Saved external predictions to:\")\n",
    "    print(\"Text:\", out_path)\n",
    "    print(\"Image:\", ext_fig_path)\n",
    "\n",
    "predict_external_images()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25afdd03-2f81-4155-a2e9-ea86054b24f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 12 – Grad-CAM (TR/EN comments only)\n",
    "# ============================================================\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# ----------------------------\n",
    "# TR: Son Conv2D katmanını otomatik bul\n",
    "# EN: Auto-detect the last Conv2D layer\n",
    "# ----------------------------\n",
    "def get_last_conv_layer_name(model: tf.keras.Model) -> str:\n",
    "    for layer in reversed(model.layers):\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            return layer.name\n",
    "    raise ValueError(\"No Conv2D layer found in the model.\")\n",
    "\n",
    "# ----------------------------\n",
    "# TR: Grad-CAM ısı haritası üret\n",
    "# EN: Generate Grad-CAM heatmap\n",
    "# ----------------------------\n",
    "def make_gradcam_heatmap(\n",
    "    img_tensor: tf.Tensor,\n",
    "    model: tf.keras.Model,\n",
    "    last_conv_layer_name: str = None,\n",
    "    class_index: int = None\n",
    "):\n",
    "    # TR: Varsayılan olarak son conv katmanı\n",
    "    # EN: Use last conv layer by default\n",
    "    if last_conv_layer_name is None:\n",
    "        last_conv_layer_name = get_last_conv_layer_name(model)\n",
    "\n",
    "    # TR: Conv çıktısı + model çıktısı veren ara model\n",
    "    # EN: Build a model that maps input -> (last_conv_output, predictions)\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    grad_model = tf.keras.Model(\n",
    "        inputs=model.inputs,\n",
    "        outputs=[last_conv_layer.output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, preds = grad_model(img_tensor, training=False)\n",
    "\n",
    "        # TR: Hedef sınıf seçimi (yoksa modelin tahmini)\n",
    "        # EN: Target class selection (if None, use predicted class)\n",
    "        if class_index is None:\n",
    "            class_index = tf.argmax(preds[0])\n",
    "\n",
    "        # TR: Sınıf skoru (softmax çıkışı)\n",
    "        # EN: Class score (softmax output)\n",
    "        class_score = preds[:, class_index]\n",
    "\n",
    "    # TR: Gradients = d(score)/d(conv_outputs)\n",
    "    # EN: Gradients = d(score)/d(conv_outputs)\n",
    "    grads = tape.gradient(class_score, conv_outputs)\n",
    "\n",
    "    # TR: Kanal ağırlıkları (global average pooling)\n",
    "    # EN: Channel weights (global average pooling)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))  # shape: (C,)\n",
    "\n",
    "    # TR: Ağırlıklı toplam\n",
    "    # EN: Weighted sum\n",
    "    conv_outputs = conv_outputs[0]  # shape: (H, W, C)\n",
    "    heatmap = tf.reduce_sum(conv_outputs * pooled_grads, axis=-1)\n",
    "\n",
    "    # TR: ReLU ve normalize\n",
    "    # EN: ReLU and normalize\n",
    "    heatmap = tf.maximum(heatmap, 0)\n",
    "    denom = tf.reduce_max(heatmap) + 1e-8\n",
    "    heatmap = heatmap / denom\n",
    "\n",
    "    return heatmap.numpy(), int(class_index)\n",
    "\n",
    "# ----------------------------\n",
    "# TR: Heatmap'i görüntüye bindir (overlay)\n",
    "# EN: Overlay heatmap on the original image\n",
    "# ----------------------------\n",
    "def overlay_gradcam(\n",
    "    img_gray: np.ndarray,\n",
    "    heatmap: np.ndarray,\n",
    "    alpha: float = 0.35\n",
    "):\n",
    "    # TR: img_gray: (H,W) veya (H,W,1) [0,1]\n",
    "    # EN: img_gray: (H,W) or (H,W,1) in [0,1]\n",
    "    if img_gray.ndim == 3:\n",
    "        img_gray = img_gray.squeeze()\n",
    "\n",
    "    h, w = img_gray.shape\n",
    "    heatmap_resized = tf.image.resize(heatmap[..., np.newaxis], (h, w)).numpy().squeeze()\n",
    "\n",
    "    # TR: Renk haritası uygula\n",
    "    # EN: Apply colormap\n",
    "    cmap = plt.get_cmap(\"jet\")\n",
    "    heatmap_rgb = cmap(heatmap_resized)[..., :3]  # drop alpha\n",
    "\n",
    "    # TR: Gri görüntüyü RGB'ye çevir\n",
    "    # EN: Convert gray image to RGB\n",
    "    img_rgb = np.stack([img_gray, img_gray, img_gray], axis=-1)\n",
    "\n",
    "    # TR: Karıştır (overlay)\n",
    "    # EN: Blend (overlay)\n",
    "    overlay = (1 - alpha) * img_rgb + alpha * heatmap_rgb\n",
    "    overlay = np.clip(overlay, 0, 1)\n",
    "    return overlay\n",
    "\n",
    "# ----------------------------\n",
    "# TR: Test setinden örneklerle Grad-CAM görselleştir ve kaydet\n",
    "# EN: Visualize & save Grad-CAM for sample test images\n",
    "# ----------------------------\n",
    "def save_gradcam_samples(\n",
    "    dataset,\n",
    "    model,\n",
    "    emotion_labels,\n",
    "    results_dir,\n",
    "    n=16,\n",
    "    filename=\"gradcam_samples_8class.jpg\",\n",
    "    target_mode=\"pred\"  # \"pred\" or \"true\"\n",
    "):\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    images, labels_one_hot = next(iter(dataset))\n",
    "    images_np = images.numpy()                  # (B,48,48,1)\n",
    "    true_ids = np.argmax(labels_one_hot.numpy(), axis=1)\n",
    "\n",
    "    preds = model.predict(images, verbose=0)\n",
    "    pred_ids = np.argmax(preds, axis=1)\n",
    "\n",
    "    last_conv_name = get_last_conv_layer_name(model)\n",
    "\n",
    "    n = min(n, images_np.shape[0])\n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    for i in range(n):\n",
    "        img = images_np[i]                      # (48,48,1) in [0,1]\n",
    "        img_tensor = tf.convert_to_tensor(img[np.newaxis, ...], dtype=tf.float32)\n",
    "\n",
    "        # TR: Hangi sınıfa göre açıklayacağımızı seç\n",
    "        # EN: Choose which class to explain\n",
    "        if target_mode == \"true\":\n",
    "            class_id = int(true_ids[i])\n",
    "        else:\n",
    "            class_id = None  # explain predicted by default\n",
    "\n",
    "        heatmap, used_class = make_gradcam_heatmap(\n",
    "            img_tensor,\n",
    "            model,\n",
    "            last_conv_layer_name=last_conv_name,\n",
    "            class_index=class_id\n",
    "        )\n",
    "\n",
    "        overlay = overlay_gradcam(img.squeeze(), heatmap, alpha=0.35)\n",
    "\n",
    "        t = emotion_labels[int(true_ids[i])]\n",
    "        p = emotion_labels[int(pred_ids[i])]\n",
    "        used = emotion_labels[int(used_class)]\n",
    "        ok = (true_ids[i] == pred_ids[i])\n",
    "\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(overlay)\n",
    "        plt.axis(\"off\")\n",
    "        # TR/EN: Title shows True / Pred / Explained-class\n",
    "        plt.title(f\"T:{t}\\nP:{p}\\nCAM:{used}\", color=(\"green\" if ok else \"red\"), fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_path = os.path.join(results_dir, filename)\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\", format=\"jpg\")\n",
    "    plt.show()\n",
    "    print(\"Saved Grad-CAM samples:\", out_path)\n",
    "\n",
    "# Example usage:\n",
    "# TR: En iyi modeli yüklemek istersen (opsiyonel)\n",
    "# EN: If you want to load the best checkpoint (optional)\n",
    "# best_model = tf.keras.models.load_model(checkpoint_path)\n",
    "\n",
    "# TR: Mevcut 'model' ile çalış\n",
    "# EN: Use the current 'model'\n",
    "save_gradcam_samples(\n",
    "    dataset=test_ds,\n",
    "    model=model,\n",
    "    emotion_labels=EMOTION_LABELS,\n",
    "    results_dir=RESULTS_DIR,\n",
    "    n=16,\n",
    "    filename=\"gradcam_samples_8class.jpg\",\n",
    "    target_mode=\"pred\"  # explain predicted class\n",
    ")\n",
    "\n",
    "# TR: Gerçek etiket üzerinden açıklama yapmak istersen:\n",
    "# EN: If you want to explain based on the true class:\n",
    "save_gradcam_samples(\n",
    "    dataset=test_ds,\n",
    "    model=model,\n",
    "    emotion_labels=EMOTION_LABELS,\n",
    "    results_dir=RESULTS_DIR,\n",
    "    n=16,\n",
    "    filename=\"gradcam_samples_TRUEclass_8class.jpg\",\n",
    "    target_mode=\"true\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
